
# Fake News Detection - Jupyter Notebook (Logistic Regression Version)
# Author: Amruta Pawar (AI/ML Internship Project)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load datasets
true_df = pd.read_csv("True.csv")
fake_df = pd.read_csv("Fake.csv")

# Label data
true_df["label"] = 1
fake_df["label"] = 0

# Combine title and text
true_df["text"] = true_df["title"] + " " + true_df["text"]
fake_df["text"] = fake_df["title"] + " " + fake_df["text"]

# Merge and shuffle
df = pd.concat([true_df, fake_df])
df = df[["text", "label"]].sample(frac=1).reset_index(drop=True)

# TF-IDF and training
X = df["text"]
y = df["label"]

vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
X_vec = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"‚úÖ Model Accuracy: {round(accuracy * 100, 2)}%")

def predict_with_risk(text):
    vec = vectorizer.transform([text])
    probs = model.predict_proba(vec)[0]
    pred = model.predict(vec)[0]

    fake_prob = probs[0]
    real_prob = probs[1]

    risk = int(fake_prob * 100)
    confidence = int(real_prob * 100)

    if pred == 0:
        print(f"üü• FAKE NEWS | Risk Score: {risk}/100")
    else:
        print(f"‚úÖ REAL NEWS | Confidence Score: {confidence}/100")

def highlight_keywords(text, top_n=5):
    vec = vectorizer.transform([text])
    feature_array = np.array(vectorizer.get_feature_names_out())
    tfidf_sorting = np.argsort(vec.toarray()).flatten()[::-1]
    top_words = feature_array[tfidf_sorting][:top_n]

    print("\n‚ö†Ô∏è Top Keywords Influencing Prediction:")
    for word in top_words:
        print("‚Ä¢", word)
